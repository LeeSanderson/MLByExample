{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifiers By Example\n",
    "\n",
    "Decision trees are one of the most intuitive algorithms in machine learning. They are commonly used for classification problems. These are problems where the goal is to assign labels to data, such as predicting if an email is spam, whether a customer will leave, or if a loan application should be approved.\n",
    "\n",
    "In this article we will explore how [SciKit Learn's Decision Trees](https://scikit-learn.org/stable/modules/tree.html) can be used to solve classification type problems by trying to predict survivors of Titanic.\n",
    "\n",
    "## How Decision Trees Work\n",
    "\n",
    "A decision tree works like a flowchart.\n",
    "\n",
    "- Each node asks a question about a feature (for example, \"Is the passenger female?\").\n",
    "- Based on the answer, the data follows a branch to the next question.\n",
    "- Eventually, the data reaches a leaf node, which represents the predicted class (such as \"Survived\" or \"Did not survive\").\n",
    "\n",
    "The important part is that machine learning is used to build this flowchart automatically.\n",
    "Instead of manually deciding which questions to ask and in what order, we train the model using labeled data. The algorithm looks at patterns in the data and figures out:\n",
    "\n",
    "- Which features are the most informative,\n",
    "- What threshold values best separate different groups,\n",
    "- And how to organize these decisions in a way that leads to accurate predictions.\n",
    "\n",
    "This makes decision trees both powerful and easy to understand. You can trace exactly how a prediction was made by following the tree's logic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Prerequisites\n",
    "\n",
    "We will by using  the `numpy`, `pandas`, and `sklearn` Python packages throughout, so let's install them and import them so they are ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet --upgrade pip \n",
    "# %pip install numpy --quiet\n",
    "# %pip install PyArrow --quiet\n",
    "# %pip install Pandas --quiet\n",
    "# %pip install scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Titanic Dataset\n",
    "\n",
    "The classic [Kaggle Titanic](https://www.kaggle.com/competitions/titanic) dataset will be used to show how decision trees  can be used to solve **classification** problems. In this case, the dataset includes Titanic passenger data (name, age, price of ticket, etc) and the problem we are trying to predict is who will survive and who not.\n",
    "\n",
    "Columns in the dataset include:\n",
    "\n",
    "| Column | Definition | Notes |\n",
    "| -------- | ------- | ------- |\n",
    "| PassengerId | The unique id of the passenger ||\n",
    "| Survived | Did the passenger survive? | 1 = Yes, 0 = No|\n",
    "| Pclass | The passenger's ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| Name | The passenger's name ||\n",
    "| Sex | The passenger's gender ||\n",
    "| Age | The passenger's age in years ||\n",
    "| SibSp | The number of siblings or spouses also onboard | Siblings = brother, sister, stepbrother, stepsister. Spouses =  husband, wife (mistresses and fiances were ignored) |\n",
    "| Parch | The number of parents or children also onboard | |\n",
    "| Ticket | The passenger's ticket number | |\n",
    "| Fare | The fair paid by the passenger for their ticket | |\n",
    "| Cabin | The passenger's cabin number | Not all passenger's had a cabin |\n",
    "| Embarked | The port that the passenger embarked from | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Titanic data is provided in a CSV file. Let's load the dataset into a `pandas` dataframe so we can manipulate is more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = pd.read_csv(\"Data/titanic_train.csv\")\n",
    "titanic_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simple analysis of the data shows `342` passengers survived and `549` perished (about `62%`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling \n",
    "\n",
    "In statistics and machine learning, variables are generally divided into two main types: **categorical** and **continuous**. Understanding the difference between these types is essential, because they are handled differently during data preprocessing and model training. \n",
    "\n",
    "**Categorical variables** are features that represent distinct groups or labels. Examples include gender (`male`, `female`), passenger class (`first`, `second`, `third`), or port of embarkation (`C`, `Q`, `S`). These variables describe qualitative attributes and do not have a meaningful numeric order or scale. In contrast, **continuous variables** represent quantitative data. They include values such as age, fare, or temperature that can take on a wide range of numerical values and support arithmetic operations like averaging and subtraction.\n",
    "\n",
    "SciKit Learn's [Decision Tree](https://scikit-learn.org/stable/modules/tree.html) does not support categorical variables (see: [#5442](https://github.com/scikit-learn/scikit-learn/issues/5442)). We therefore need to convert categorical variables into a suitable format. One of the most common techniques for this is **one-hot encoding**, which transforms each unique category into its own binary (0 or 1) column. For example, a `Sex` column with the values `male` and `female` would be split into two new columns: `Sex_male` and `Sex_female`. Each row would have a 1 in the column that matches the category and a 0 in the other. This allows models to use categorical information without treating the values as numeric or ordered, and avoids introducing unintended relationships between categories.\n",
    "\n",
    "| Sex | Sex_male | Sex_female |\n",
    "| -------- | ------- | ------- |\n",
    "| male | 1 | 0 |\n",
    "| female | 0 | 1 |\n",
    "\n",
    "\n",
    "Next we define a utility function to perform **one-hot encoding** on a given column of a dataframe. We will use this in the subsequent analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(df : pd.DataFrame, column_name: str) -> tuple[pd.DataFrame, list[str]]:\n",
    "    categories = [f\"{column_name}_{value}\" for value in df[column_name].unique()]\n",
    "\n",
    "    # remove the categorical variables (if we previous called onehot_encode)\n",
    "    df = df.drop(categories, axis=1, errors=\"ignore\") \n",
    "    temp_column_name = f\"{column_name}_Temp\"\n",
    "\n",
    "    # get_dummies will remove the original column, so copy the data to temp column\n",
    "    df[temp_column_name] = df[column_name] \n",
    "    df = pd.get_dummies(df, prefix=column_name, columns=[temp_column_name], dtype=float)\n",
    "    return df, categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Survivors: Women and children first\n",
    "\n",
    "Our first hypothesis will be that woman and children were more likely to be given a place on the lifeboats and therefore will have survived. Based on this hypothesis we will use the `Sex` and `Age` columns as predictors of survival.\n",
    "\n",
    "Let's apply our new `onehot_encode` function to convert the `Sex` column to trainable parameters `Sex_male` and `Sex_female`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex_male  Sex_female\n",
       "1.0       0.0           577\n",
       "0.0       1.0           314\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "titanic_data, gender_categories = onehot_encode(titanic_data, \"Sex\")\n",
    "titanic_data[gender_categories].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into training and validation data sets\n",
    "\n",
    "When building a machine learning model, it's important to test how well it performs on new, unseen data and not just the data it was trained on. This helps us understand whether the model is actually learning meaningful patterns, or simply memorizing the training data.\n",
    "\n",
    "To do this, we split the dataset into two parts:\n",
    "\n",
    "- Training set: This is the portion of the data the model uses to learn. It sees the input features and corresponding labels, and uses them to build internal rules—like how to split the decision tree.\n",
    "- Validation set (sometimes called a test set): This is a separate portion of the data that the model does not see during training. After the model is trained, we use the validation set to evaluate how well it performs on data it hasn't encountered before.\n",
    "\n",
    "\n",
    "This split helps prevent overfitting, which happens when a model performs very well on the training data but poorly on new data. By testing on a validation set, we get a more realistic measure of how well our model is likely to perform in real-world scenarios.\n",
    "\n",
    "When we split data into training and validation sets, we want each set to be a **fair representation** of the full dataset. This is especially important when it comes to the **target label** we are trying to predict. Stratification helps ensure that the distribution of this label is consistent across both sets.\n",
    "\n",
    "In the Titanic dataset, the target label is `Survived`, which tells us whether a passenger lived or died. This dataset is imbalanced because more passengers died than survived. If we split the data randomly, we might end up with a training set that contains mostly non-survivors or a validation set with very few survivors. This imbalance can distort how the model learns and lead to unreliable performance metrics.\n",
    "\n",
    "Stratified sampling helps solve this problem by preserving the proportion of classes in each split. For example, if about 38% of passengers survived in the full dataset, stratification ensures that the training and validation sets also contain approximately 38% survivors. This makes sure the model is trained and tested on data that reflects the true class distribution.\n",
    "\n",
    "In Scikit-Learn, we can use the stratify parameter in the `train_test_split()` function to enable this behavior. \n",
    "\n",
    "Here’s how it looks when we split the data so that we have 80% training data and 20% validation data (`test_size=0.2`), stratify the data using the `Survived` column, and set the `random_state` to a fixed value (so that every time we run the code, we get the same split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = (\n",
    "    train_test_split(\n",
    "        titanic_data, \n",
    "        test_size=0.2, \n",
    "        stratify=titanic_data[\"Survived\"], \n",
    "        random_state=42)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- Sex_male <= 0.50\n",
      "|   |--- Age <= 14.75\n",
      "|   |   |--- class: 1\n",
      "|   |--- Age >  14.75\n",
      "|   |   |--- class: 1\n",
      "|--- Sex_male >  0.50\n",
      "|   |--- Age <= 3.50\n",
      "|   |   |--- class: 1\n",
      "|   |--- Age >  3.50\n",
      "|   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictors = [\"Age\"] + gender_categories\n",
    "prediction = \"Survived\"\n",
    "\n",
    "x = train[predictors]\n",
    "y = train[[prediction]].values\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "decision_tree.fit(x, y)\n",
    "\n",
    "print(tree.export_text(decision_tree, feature_names=predictors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Now that we have trained our decision tree, one of the first things we check is its accuracy i.e. the percentage of correct predictions the model makes on the validation set. But how do we know if that accuracy is actually meaningful?\n",
    "\n",
    "A helpful baseline is to compare the model's accuracy to the accuracy of a random guess. In a binary classification problem like predicting Titanic survival (`Survived = 0` or `1`), a random guess would mean selecting either class with equal probability. This is similar to flipping a coin, which gives an expected accuracy of around 50%.\n",
    "\n",
    "However, the Titanic dataset is imbalanced. More passengers died than survived. This means that even a simple strategy like always predicting the majority class (in this case, \"Did not survive\") can perform better than random. We know from the analysis we did above that approximately 62% of the passengers did not survive, always predicting \"Did not survive\" would be correct 62% of the time. This is called the majority class baseline.\n",
    "\n",
    "So when we evaluate our model, we should ask two questions:\n",
    "\n",
    "- Is the accuracy better than a random guess, which would be about 50%?\n",
    "- Is the accuracy better than always guessing the majority class, which would be around 62% in this dataset?\n",
    "\n",
    "Let's evaluate our simple model to see how accurate it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple \"Women and children first\" hypothesis has accuracy of: 75.98%\n"
     ]
    }
   ],
   "source": [
    "predictions = decision_tree.predict(validate[predictors])\n",
    "actuals = validate[[prediction]].values\n",
    "\n",
    "score = accuracy_score(actuals, predictions)\n",
    "print(f'Simple \"Women and children first\" hypothesis has accuracy of: {score *100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our decision tree achieves an accuracy significantly higher than these baselines. Therefore we can be confident that the model is learning meaningful patterns from the data instead of simply guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Predictions: Is class a factor?\n",
    "\n",
    "Let's see if we can improve the accuracy of our decision tree by adding the ticket class into the model.\n",
    "Our hypothesis here is that 1st class passengers are closer to the lifeboats and will more easily be able to reach them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass_3  Pclass_1  Pclass_2\n",
       "1.0       0.0       0.0         491\n",
       "0.0       1.0       0.0         216\n",
       "          0.0       1.0         184\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data, class_categories = onehot_encode(titanic_data, \"Pclass\")\n",
    "titanic_data[class_categories].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- Sex_male <= 0.50\n",
      "|   |--- Pclass_3 <= 0.50\n",
      "|   |   |--- Age <= 2.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- Age >  2.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |--- Pclass_3 >  0.50\n",
      "|   |   |--- Age <= 36.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- Age >  36.50\n",
      "|   |   |   |--- class: 0\n",
      "|--- Sex_male >  0.50\n",
      "|   |--- Age <= 6.50\n",
      "|   |   |--- Pclass_3 <= 0.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- Pclass_3 >  0.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- Age >  6.50\n",
      "|   |   |--- Pclass_1 <= 0.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- Pclass_1 >  0.50\n",
      "|   |   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, validate = train_test_split(titanic_data, test_size=0.2, random_state=42)\n",
    "predictors = [\"Age\"] + gender_categories + class_categories\n",
    "prediction = \"Survived\"\n",
    "\n",
    "x = train[predictors]\n",
    "y = train[[prediction]].values\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "decision_tree.fit(x, y)\n",
    "\n",
    "print(tree.export_text(decision_tree, feature_names=predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Women and children first (as long as you are 1st class)\" hypothesis has accuracy of: 80.45%\n"
     ]
    }
   ],
   "source": [
    "predictions = decision_tree.predict(validate[predictors])\n",
    "actuals = validate[[prediction]].values\n",
    "\n",
    "score = accuracy_score(actuals, predictions)\n",
    "print(f'\"Women and children first (as long as you are 1st class)\" hypothesis has accuracy of: {score *100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
