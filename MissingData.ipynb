{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data\n",
    "\n",
    "A simple exploration of missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet --upgrade pip \n",
    "# %pip install numpy --quiet\n",
    "# %pip install PyArrow --quiet\n",
    "# %pip install Pandas --quiet\n",
    "# %pip install scikit-learn --quiet\n",
    "# %pip install missingno --quiet\n",
    "# %pip install statsmodels --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Missing Data\n",
    "\n",
    "The first step in handling missing data is to identify where and how data is missing. In **Pandas**, this can be done using the `isna()` or `isnull()` functions. \n",
    "\n",
    "It can be confusion that these two functions that do exactly the same thing, but if we check the [source code of Pandas](https://github.com/pandas-dev/pandas/blob/0409521665bd436a10aea7e06336066bf07ff057/pandas/core/dtypes/missing.py#L109) we can see that `isnull()` is just an alias for `isna()`.  As a best practice, I always prefer to use `isna()` over `isnull()`. In **Pandas** there are other similar method names like `dropna()` and  `fillna()` that handles missing values and it always helps to remember easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  income\n",
      "0  False   False\n",
      "1  False    True\n",
      "2   True   False\n",
      "3  False   False\n",
      "4  False   False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'age': [25, 30, None, 40, 50],\n",
    "        'income': [50000, None, 60000, 70000, 80000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Identify missing values\n",
    "missing_data = df.isnull()\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little's MCAR Test\n",
    "\n",
    "[Little's MCAR test](https://wiki.q-researchsoftware.com/wiki/Missing_Data_-_Little%27s_MCAR_Test) is used to assess whether data is **Missing Completely at Random (MCAR)**. The test evaluates if the probability of missing data is independent of the observed data values. If the test result is **non-significant** (i.e., p-value > 0.05), it suggests that the data is MCAR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def little_mcar_test(data : pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Implementation of Little's MCAR test\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Dataset with missing values. `n` rows (samples) and `m` columns (features).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pvalue : float\n",
    "        The p-value of a chi-square hypothesis test. Null hypothesis: data is Missing Completely At Random (MCAR). Alternative hypothesis: data is not MCAR.\n",
    "        A p-value > 0.05 suggests that missing values in the column are likely MCAR.\n",
    "    \"\"\"\n",
    "    overall_means = data.mean()\n",
    "    variances = data.var()\n",
    "    chi_squared_stat = 0\n",
    "    degrees_of_fredom = 0\n",
    "\n",
    "    pattern_groups = data.groupby(data.apply(lambda row: tuple(row.isna()), axis=1))\n",
    "    for pattern, group in pattern_groups:\n",
    "        observed_columns = ~np.array(pattern)\n",
    "        group_means = group.mean()\n",
    "        residuals = group_means[observed_columns] - overall_means[observed_columns]\n",
    "        \n",
    "        group_size = len(group)\n",
    "        group_variance = variances[observed_columns]\n",
    "        chi_squared_contribution = np.sum((group_size * (residuals ** 2)) / group_variance)\n",
    "\n",
    "        chi_squared_stat += chi_squared_contribution\n",
    "        degrees_of_fredom += len(observed_columns.nonzero()[0]) - 1  # Number of observed variables - 1\n",
    "\n",
    "    p_value  = 1- chi2.cdf(chi_squared_stat, degrees_of_fredom)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Generate 100 samples of ages and incomes where income is correlated with age (with some variance) \n",
    "min_age, max_age, number_of_samples = 20, 80, 100\n",
    "ages = [random.randint(min_age, max_age) for _ in range(number_of_samples)]\n",
    "min_income, max_income, income_variance = 30000, 80000, 10000\n",
    "income_range = max_income - min_income\n",
    "age_range = max_age - min_age\n",
    "min_base_income, max_base_income = min_income - income_variance, min_income + income_variance\n",
    "incomes = [\n",
    "    int(random.randint(min_base_income, max_base_income) + (((age - min_age) / age_range) * income_range)) \n",
    "    for age in ages\n",
    "]\n",
    "\n",
    "# Set 10% of the values to None randomly\n",
    "ten_percent_of_incomes = int(0.1 * len(incomes))\n",
    "random_indices = random.sample(range(len(incomes)), ten_percent_of_incomes)\n",
    "randomly_null_incomes = [None if i in random_indices else income for i, income in enumerate(incomes)]\n",
    "\n",
    "df = pd.DataFrame({'age': ages, 'income': randomly_null_incomes })\n",
    "p_value = little_mcar_test(df)\n",
    "print(\"For randomly_null_incomes data frame:\")\n",
    "print(f\"Missing values are likely missing completely at random (p_value = {p_value})\" \n",
    "      if p_value > 0.05 else \n",
    "      f\"Missing values are not missing completly at random (p_value = {p_value})\")\n",
    "\n",
    "# Set 70% of the values over 70,000 to None - indicating some correlation between age and salary\n",
    "indices_over_70000 = [i for i, income in enumerate(incomes) if income > 70000]\n",
    "seventy_percent_of_incomes_over_70000 = int(0.7 * len(indices_over_70000))\n",
    "random_indices_over_70000 = random.sample(indices_over_70000, seventy_percent_of_incomes_over_70000)\n",
    "randomly_null_incomes_over_70000 = [None if i in random_indices_over_70000 else income for i, income in enumerate(incomes)]\n",
    "\n",
    "df = pd.DataFrame({'age': ages, 'income': randomly_null_incomes_over_70000 })\n",
    "p_value = little_mcar_test(df)\n",
    "print(\"For randomly_null_incomes_over_70000 data frame:\")\n",
    "print(f\"Missing values are likely missing completely at random (p_value = {p_value})\" \n",
    "      if p_value > 0.05 else \n",
    "      f\"Missing values are not missing completly at random (p_value = {p_value})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling MCAR Missing Data\n",
    "\n",
    "For data that is **Missing completely at random (MCAR)**, you can often drop the rows or columns with missing values without introducing significant bias into your analysis, as MCAR data does not show systematic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age   income\n",
      "0  25.0  50000.0\n",
      "3  40.0  70000.0\n",
      "4  50.0  80000.0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age   income\n",
      "0  25.00  50000.0\n",
      "1  30.00  65000.0\n",
      "2  36.25  60000.0\n",
      "3  40.00  70000.0\n",
      "4  50.00  80000.0\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values with the column mean\n",
    "df['age'] = df['age'].fillna(df['age'].mean())\n",
    "df['income'] = df['income'].fillna(df['income'].mean())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling MAR Missing Data\n",
    "\n",
    "When data is **Missing at random (MAR)**, imputing missing values based on other observed variables is often the best approach. Techniques like **regression imputation** or **k-nearest neighbours (KNN) imputation** are commonly used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        income\n",
      "0   25  50000.000000\n",
      "1   30  55769.230769\n",
      "2   35  60000.000000\n",
      "3   40  70000.000000\n",
      "4   50  80000.000000\n"
     ]
    }
   ],
   "source": [
    "# Imputation using linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample data\n",
    "data = {'age': [25, 30, 35, 40, 50],\n",
    "        'income': [50000, None, 60000, 70000, 80000]}\n",
    "degrees_of_freedom = pd.DataFrame(data)\n",
    "\n",
    "# Assuming we are imputing 'income' based on 'age'\n",
    "model = LinearRegression()\n",
    "\n",
    "# Drop rows with missing 'income' and use 'age' to predict 'income'\n",
    "train_data = degrees_of_freedom.dropna(subset=['income'])\n",
    "X_train = train_data[['age']]\n",
    "y_train = train_data['income']\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict missing 'income' values\n",
    "degrees_of_freedom.loc[degrees_of_freedom['income'].isnull(), 'income'] = model.predict(degrees_of_freedom.loc[degrees_of_freedom['income'].isnull(), ['age']])\n",
    "print(degrees_of_freedom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age   income\n",
      "0  25.0  50000.0\n",
      "1  30.0  55000.0\n",
      "2  35.0  60000.0\n",
      "3  40.0  70000.0\n",
      "4  50.0  80000.0\n"
     ]
    }
   ],
   "source": [
    "# Imputation using KNN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Sample data\n",
    "data = {'age': [25, 30, 35, 40, 50],\n",
    "        'income': [50000, None, 60000, 70000, 80000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use 2 nearest neighbors to fill missing data.\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "df[['age', 'income']] = knn_imputer.fit_transform(df[['age', 'income']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling MNAR Missing Data\n",
    "\n",
    "Handling **Missing Not at Random (MNAR)** data is the most challenging, as the missingness is related to the value of the missing data itself or some unobserved factor. The best approach often requires domain expertise or external data to model the missingness properly. However, one common strategy is to **impute with a constant** or create a separate indicator variable to flag the missingness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age   income  income_missing\n",
      "0   25  50000.0               0\n",
      "1   30      0.0               1\n",
      "2   35  60000.0               0\n",
      "3   40  70000.0               0\n",
      "4   50  80000.0               0\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {'age': [25, 30, 35, 40, 50], 'income': [50000, None, 60000, 70000, 80000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a flag for missing 'income' data\n",
    "df['income_missing'] = df['income'].isnull().astype(int)\n",
    "\n",
    "# Impute 'income' with a constant or domain-based value\n",
    "df['income'] = df['income'].fillna(0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also use **Multiple Imputation by Chained Equations (MICE)**, which accounts for uncertainty in the missing data by creating multiple plausible imputations.\n",
    "`scikit-learn` `IterativeImputer` can be used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age   income   bmi\n",
      "0  25.0  50000.0  22.5\n",
      "1  30.0  60000.0  24.0\n",
      "2   NaN      NaN  23.5\n",
      "3  40.0  70000.0   NaN\n",
      "4  50.0  80000.0  27.0\n",
      "         age        income        bmi\n",
      "0  25.000000  50000.000000  22.500000\n",
      "1  30.000000  60000.000000  24.000000\n",
      "2  31.872197  59493.007701  23.500000\n",
      "3  40.000000  70000.000000  25.413455\n",
      "4  50.000000  80000.000000  27.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leeco\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\impute\\_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "data = {\n",
    "    'age': [25, 30, None, 40, 50],\n",
    "    'income': [50000, 60000, None, 70000, 80000],\n",
    "    'bmi': [22.5, 24.0, 23.5, None, 27.0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply MICE to impute missing values. Note: MICE works only on numeric data\n",
    "mice_imputer = IterativeImputer()\n",
    "df_imputed = df.copy()\n",
    "df_imputed.iloc[:, :] = mice_imputer.fit_transform(df)\n",
    "\n",
    "\n",
    "print(df)\n",
    "print(df_imputed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
