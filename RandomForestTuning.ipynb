{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ae67ae",
   "metadata": {},
   "source": [
    "# Tuning Random Forests\n",
    "\n",
    "The `RandomForestClassifier` in scikit-learn has many parameters, and choosing the best ones can significantly impact your model's performance. Here's a systematic approach to tuning those parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25dcba6",
   "metadata": {},
   "source": [
    "## Python Prerequisites\n",
    "\n",
    "Let's install and import the prerequisites so they are ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fda44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet --upgrade pip \n",
    "# %pip install numpy --quiet\n",
    "# %pip install PyArrow --quiet\n",
    "# %pip install Pandas --quiet\n",
    "# %pip install scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72fe77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from helpers.onehot_encode import onehot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b8f1b",
   "metadata": {},
   "source": [
    "\n",
    "## Starting with a Baseline\n",
    "\n",
    "For starters, let's train a `RandomForestClassifier` on the trusty Titanic dataset to get an understanding of how well the _default parameters_ do at predicting the accuracy of survivors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"Data/titanic_train.csv\")\n",
    "\n",
    "titanic_data, gender_categories = onehot_encode(titanic_data, \"Sex\")\n",
    "titanic_data, class_categories = onehot_encode(titanic_data, \"Pclass\")\n",
    "predictors = [\"Age\", \"Fare\"] + gender_categories + class_categories\n",
    "prediction = \"Survived\"\n",
    "\n",
    "train, validate = (\n",
    "    train_test_split(\n",
    "        titanic_data, \n",
    "        test_size=0.2, \n",
    "        stratify=titanic_data[prediction], \n",
    "        random_state=42)\n",
    "    )\n",
    "\n",
    "x = train[predictors]\n",
    "y = train[[prediction]].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b58d130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model accuracy: 84.36%\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(x, y)\n",
    "\n",
    "predictions = random_forest.predict(validate[predictors])\n",
    "actuals = validate[[prediction]].values\n",
    "\n",
    "score = accuracy_score(actuals, predictions)\n",
    "print(f'Baseline model accuracy: {score *100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376898",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`84.36%` accuracy. Not a bad start.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010959d",
   "metadata": {},
   "source": [
    "\n",
    "## RandomForestClassifier parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f0431",
   "metadata": {},
   "source": [
    "In GridSearchCV, stratification is handled automatically if:\n",
    "\n",
    "- You're doing classification\n",
    "- You pass y (the target labels) when calling .fit()\n",
    "- You use an integer for cv (e.g., cv=5)\n",
    "\n",
    "scikit-learn will automatically use StratifiedKFold under the hood for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f2d55e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n",
      "Best Parameters: {'n_estimators': 84, 'n_jobs': -1}\n",
      "Best accuracy: 0.8272760581025659\n",
      "Validation accuracy: 84.3575%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [i + 40 for i in range(200)], #[45, 50, 100, 104, 200],                       # small, default, and larger\n",
    "    # 'max_depth': [None, 10, 3],                      # default, moderate, shallow (bad)\n",
    "    # 'min_samples_split': [2, 10, 50],                # default, medium, large (underfit)\n",
    "    # 'min_samples_leaf': [1, 5, 20],                  # default, medium, large (underfit)\n",
    "    # 'max_features': ['sqrt', 10, None],              # default, moderate, all (may overfit)\n",
    "    # 'class_weight': [None, 'balanced']  # default, important for imbalance\n",
    "    'n_jobs': [-1],  # use all available cores\n",
    "}\n",
    "rf2 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf2, param_grid=param_grid, cv=cv, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)\n",
    "\n",
    "\n",
    "predictions = grid_search.best_estimator_.predict(validate[predictors])\n",
    "actuals = validate[[prediction]].values\n",
    "\n",
    "score = accuracy_score(actuals, predictions)\n",
    "print(f'Validation accuracy: {score *100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5f4f6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'n_estimators': 84, 'n_jobs': -1}</td>\n",
       "      <td>84</td>\n",
       "      <td>0.827276</td>\n",
       "      <td>0.015425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'n_estimators': 83, 'n_jobs': -1}</td>\n",
       "      <td>83</td>\n",
       "      <td>0.825870</td>\n",
       "      <td>0.015191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'n_estimators': 42, 'n_jobs': -1}</td>\n",
       "      <td>42</td>\n",
       "      <td>0.824475</td>\n",
       "      <td>0.018575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                params  param_n_estimators  mean_test_score  \\\n",
       "44  {'n_estimators': 84, 'n_jobs': -1}                  84         0.827276   \n",
       "43  {'n_estimators': 83, 'n_jobs': -1}                  83         0.825870   \n",
       "2   {'n_estimators': 42, 'n_jobs': -1}                  42         0.824475   \n",
       "\n",
       "    std_test_score  \n",
       "44        0.015425  \n",
       "43        0.015191  \n",
       "2         0.018575  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)[['params', 'param_n_estimators', 'mean_test_score', 'std_test_score']]\n",
    "results.sort_values(by='mean_test_score', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284cc475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b683d7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.210664</td>\n",
       "      <td>0.349601</td>\n",
       "      <td>0.029481</td>\n",
       "      <td>-0.020006</td>\n",
       "      <td>-0.601959</td>\n",
       "      <td>1.726634</td>\n",
       "      <td>2.573545</td>\n",
       "      <td>0.223895</td>\n",
       "      <td>-1.636214</td>\n",
       "      <td>2.394204</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.655477</td>\n",
       "      <td>-1.486167</td>\n",
       "      <td>0.487789</td>\n",
       "      <td>-0.580844</td>\n",
       "      <td>-0.122460</td>\n",
       "      <td>-0.840531</td>\n",
       "      <td>-1.624671</td>\n",
       "      <td>-0.034947</td>\n",
       "      <td>-0.622731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.634961</td>\n",
       "      <td>0.223648</td>\n",
       "      <td>-1.196056</td>\n",
       "      <td>0.417422</td>\n",
       "      <td>0.214757</td>\n",
       "      <td>-0.207356</td>\n",
       "      <td>0.756490</td>\n",
       "      <td>-1.306920</td>\n",
       "      <td>0.880136</td>\n",
       "      <td>0.263538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837681</td>\n",
       "      <td>-1.260614</td>\n",
       "      <td>-0.582005</td>\n",
       "      <td>0.137562</td>\n",
       "      <td>-1.121255</td>\n",
       "      <td>0.474646</td>\n",
       "      <td>-1.387886</td>\n",
       "      <td>-0.479281</td>\n",
       "      <td>0.294088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.572048</td>\n",
       "      <td>0.431379</td>\n",
       "      <td>1.672453</td>\n",
       "      <td>-0.164474</td>\n",
       "      <td>1.428403</td>\n",
       "      <td>-0.604543</td>\n",
       "      <td>-4.224891</td>\n",
       "      <td>-1.177700</td>\n",
       "      <td>0.564690</td>\n",
       "      <td>0.600523</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.320712</td>\n",
       "      <td>-1.710154</td>\n",
       "      <td>0.712096</td>\n",
       "      <td>-0.637608</td>\n",
       "      <td>-0.362928</td>\n",
       "      <td>0.592051</td>\n",
       "      <td>-0.613427</td>\n",
       "      <td>-2.880198</td>\n",
       "      <td>-0.314463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.534496</td>\n",
       "      <td>1.087456</td>\n",
       "      <td>0.790938</td>\n",
       "      <td>-1.757833</td>\n",
       "      <td>-0.061646</td>\n",
       "      <td>-0.390053</td>\n",
       "      <td>0.416728</td>\n",
       "      <td>0.148818</td>\n",
       "      <td>0.335285</td>\n",
       "      <td>0.131284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.346023</td>\n",
       "      <td>-1.254552</td>\n",
       "      <td>-0.574714</td>\n",
       "      <td>1.477617</td>\n",
       "      <td>-1.997026</td>\n",
       "      <td>-0.170192</td>\n",
       "      <td>-0.058041</td>\n",
       "      <td>1.908746</td>\n",
       "      <td>1.838352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.543131</td>\n",
       "      <td>0.109050</td>\n",
       "      <td>-1.856372</td>\n",
       "      <td>-1.382639</td>\n",
       "      <td>-1.772783</td>\n",
       "      <td>-0.422195</td>\n",
       "      <td>3.203891</td>\n",
       "      <td>-0.979045</td>\n",
       "      <td>0.287339</td>\n",
       "      <td>0.968977</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.215352</td>\n",
       "      <td>-0.333146</td>\n",
       "      <td>1.356225</td>\n",
       "      <td>-0.026778</td>\n",
       "      <td>0.782405</td>\n",
       "      <td>-0.352308</td>\n",
       "      <td>2.401678</td>\n",
       "      <td>4.205997</td>\n",
       "      <td>-0.641665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.303397</td>\n",
       "      <td>-0.568428</td>\n",
       "      <td>-0.072603</td>\n",
       "      <td>0.655341</td>\n",
       "      <td>0.178053</td>\n",
       "      <td>0.705260</td>\n",
       "      <td>-0.951625</td>\n",
       "      <td>1.592417</td>\n",
       "      <td>-0.260190</td>\n",
       "      <td>0.145472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.911432</td>\n",
       "      <td>0.522614</td>\n",
       "      <td>-0.449445</td>\n",
       "      <td>0.259839</td>\n",
       "      <td>-2.098249</td>\n",
       "      <td>-0.992923</td>\n",
       "      <td>-1.809622</td>\n",
       "      <td>-2.714639</td>\n",
       "      <td>-1.587788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>-0.137859</td>\n",
       "      <td>-0.383533</td>\n",
       "      <td>1.923109</td>\n",
       "      <td>0.618716</td>\n",
       "      <td>-1.203447</td>\n",
       "      <td>0.286761</td>\n",
       "      <td>3.544024</td>\n",
       "      <td>-0.808329</td>\n",
       "      <td>-0.489768</td>\n",
       "      <td>-0.363143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642698</td>\n",
       "      <td>-3.574396</td>\n",
       "      <td>-0.027515</td>\n",
       "      <td>0.049381</td>\n",
       "      <td>-1.132985</td>\n",
       "      <td>2.430925</td>\n",
       "      <td>-0.681227</td>\n",
       "      <td>0.240363</td>\n",
       "      <td>-0.243601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.588165</td>\n",
       "      <td>-0.394008</td>\n",
       "      <td>-0.548438</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>0.041069</td>\n",
       "      <td>1.213395</td>\n",
       "      <td>-0.364276</td>\n",
       "      <td>1.535406</td>\n",
       "      <td>-0.341339</td>\n",
       "      <td>-0.052770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181754</td>\n",
       "      <td>-1.706225</td>\n",
       "      <td>-1.002879</td>\n",
       "      <td>0.279353</td>\n",
       "      <td>-1.201080</td>\n",
       "      <td>-0.057721</td>\n",
       "      <td>-1.237656</td>\n",
       "      <td>-0.628472</td>\n",
       "      <td>-0.501242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.681884</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.474925</td>\n",
       "      <td>-0.258151</td>\n",
       "      <td>-0.695408</td>\n",
       "      <td>0.364455</td>\n",
       "      <td>-4.467280</td>\n",
       "      <td>-1.068672</td>\n",
       "      <td>0.356080</td>\n",
       "      <td>-0.153367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.793321</td>\n",
       "      <td>0.842952</td>\n",
       "      <td>3.032088</td>\n",
       "      <td>0.035651</td>\n",
       "      <td>1.010222</td>\n",
       "      <td>-1.524072</td>\n",
       "      <td>-1.579162</td>\n",
       "      <td>-3.917595</td>\n",
       "      <td>-1.015519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.655273</td>\n",
       "      <td>1.857486</td>\n",
       "      <td>-0.146555</td>\n",
       "      <td>-2.115613</td>\n",
       "      <td>-1.191785</td>\n",
       "      <td>0.315962</td>\n",
       "      <td>0.657840</td>\n",
       "      <td>0.660862</td>\n",
       "      <td>0.719351</td>\n",
       "      <td>-1.220327</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.312645</td>\n",
       "      <td>-1.928418</td>\n",
       "      <td>0.070396</td>\n",
       "      <td>0.808852</td>\n",
       "      <td>1.251117</td>\n",
       "      <td>0.252184</td>\n",
       "      <td>-0.385290</td>\n",
       "      <td>-0.723054</td>\n",
       "      <td>0.841412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0       1.210664   0.349601   0.029481  -0.020006  -0.601959   1.726634   \n",
       "1       0.634961   0.223648  -1.196056   0.417422   0.214757  -0.207356   \n",
       "2      -0.572048   0.431379   1.672453  -0.164474   1.428403  -0.604543   \n",
       "3       0.534496   1.087456   0.790938  -1.757833  -0.061646  -0.390053   \n",
       "4      -0.543131   0.109050  -1.856372  -1.382639  -1.772783  -0.422195   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "19995   0.303397  -0.568428  -0.072603   0.655341   0.178053   0.705260   \n",
       "19996  -0.137859  -0.383533   1.923109   0.618716  -1.203447   0.286761   \n",
       "19997   0.588165  -0.394008  -0.548438   0.041910   0.041069   1.213395   \n",
       "19998   0.681884   0.004827   0.474925  -0.258151  -0.695408   0.364455   \n",
       "19999   0.655273   1.857486  -0.146555  -2.115613  -1.191785   0.315962   \n",
       "\n",
       "       feature_6  feature_7  feature_8  feature_9  ...  feature_21  \\\n",
       "0       2.573545   0.223895  -1.636214   2.394204  ...   -1.655477   \n",
       "1       0.756490  -1.306920   0.880136   0.263538  ...    0.837681   \n",
       "2      -4.224891  -1.177700   0.564690   0.600523  ...   -1.320712   \n",
       "3       0.416728   0.148818   0.335285   0.131284  ...    1.346023   \n",
       "4       3.203891  -0.979045   0.287339   0.968977  ...   -2.215352   \n",
       "...          ...        ...        ...        ...  ...         ...   \n",
       "19995  -0.951625   1.592417  -0.260190   0.145472  ...   -0.911432   \n",
       "19996   3.544024  -0.808329  -0.489768  -0.363143  ...    0.642698   \n",
       "19997  -0.364276   1.535406  -0.341339  -0.052770  ...    0.181754   \n",
       "19998  -4.467280  -1.068672   0.356080  -0.153367  ...   -0.793321   \n",
       "19999   0.657840   0.660862   0.719351  -1.220327  ...   -1.312645   \n",
       "\n",
       "       feature_22  feature_23  feature_24  feature_25  feature_26  feature_27  \\\n",
       "0       -1.486167    0.487789   -0.580844   -0.122460   -0.840531   -1.624671   \n",
       "1       -1.260614   -0.582005    0.137562   -1.121255    0.474646   -1.387886   \n",
       "2       -1.710154    0.712096   -0.637608   -0.362928    0.592051   -0.613427   \n",
       "3       -1.254552   -0.574714    1.477617   -1.997026   -0.170192   -0.058041   \n",
       "4       -0.333146    1.356225   -0.026778    0.782405   -0.352308    2.401678   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "19995    0.522614   -0.449445    0.259839   -2.098249   -0.992923   -1.809622   \n",
       "19996   -3.574396   -0.027515    0.049381   -1.132985    2.430925   -0.681227   \n",
       "19997   -1.706225   -1.002879    0.279353   -1.201080   -0.057721   -1.237656   \n",
       "19998    0.842952    3.032088    0.035651    1.010222   -1.524072   -1.579162   \n",
       "19999   -1.928418    0.070396    0.808852    1.251117    0.252184   -0.385290   \n",
       "\n",
       "       feature_28  feature_29  target  \n",
       "0       -0.034947   -0.622731       0  \n",
       "1       -0.479281    0.294088       0  \n",
       "2       -2.880198   -0.314463       0  \n",
       "3        1.908746    1.838352       0  \n",
       "4        4.205997   -0.641665       0  \n",
       "...           ...         ...     ...  \n",
       "19995   -2.714639   -1.587788       0  \n",
       "19996    0.240363   -0.243601       0  \n",
       "19997   -0.628472   -0.501242       0  \n",
       "19998   -3.917595   -1.015519       0  \n",
       "19999   -0.723054    0.841412       0  \n",
       "\n",
       "[20000 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create a synthetic dataset for demonstration purposes\n",
    "# where we have a highly imbalanced dataset\n",
    "# with 20,000 samples, 30 features, and a very small percentage of positive samples\n",
    "X, y = make_classification(\n",
    "    n_samples=20000,\n",
    "    n_features=30,\n",
    "    n_informative=6,\n",
    "    n_redundant=2,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    weights=[0.995, 0.005],  # ~0.5% positives (very imbalanced)\n",
    "    class_sep=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "df['target'] = y\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
